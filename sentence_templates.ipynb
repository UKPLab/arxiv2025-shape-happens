{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name list generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer\n",
    "\n",
    "names = [\n",
    "    \"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Ethan\", \"Fiona\", \"George\", \"Hannah\",\n",
    "    \"Isaac\", \"Julia\", \"Kevin\", \"Laura\", \"Michael\", \"Nina\", \"Oliver\", \"Paula\",\n",
    "    \"Quentin\", \"Rachel\", \"Samuel\", \"Tina\", \"Umar\", \"Vera\", \"William\", \"Xena\",\n",
    "    \"Yusuf\", \"Zara\", \"Aaron\", \"Bianca\", \"Caleb\", \"Denise\", \"Elijah\", \"Faith\",\n",
    "    \"Gavin\", \"Hailey\", \"Ian\", \"Jasmine\", \"Kyle\", \"Lena\", \"Martin\", \"Nora\",\n",
    "    \"Owen\", \"Penelope\", \"Quinn\", \"Rose\", \"Sebastian\", \"Talia\", \"Uri\", \"Valerie\",\n",
    "    \"Wesley\", \"Xander\", \"Yara\", \"Zane\", \"Amira\", \"Diego\", \"Liam\", \"Noah\",\n",
    "    \"Sofia\", \"Mateo\", \"Aaliyah\", \"Levi\", \"Mohammed\", \"Priya\", \"Jorge\", \"Akira\",\n",
    "    \"Fatima\", \"Chang\", \"Layla\", \"Anika\", \"Raj\", \"Mei\", \"Imani\", \"Kenji\",\n",
    "    \"Adriana\", \"Santiago\", \"Lucia\", \"Mila\", \"Khalid\", \"Jin\", \"Zane\", \"Sasha\",\n",
    "    \"Giovanni\", \"Ines\", \"Tariq\", \"Naomi\", \"Reza\", \"Lina\", \"Omar\", \"Tanvi\",\n",
    "    \"Marco\", \"Soraya\", \"Arjun\", \"Dmitri\", \"Salma\", \"Thiago\", \"Yuna\", \"Niko\",\n",
    "    \"Carmen\", \"Ishaan\", \"Aliyah\", \"Hiro\", \"Luca\", \"Samira\", \"Fernando\", \"Alina\",\n",
    "    \"Dalia\", \"Ravi\", \"Zara\", \"Emilio\", \"Kira\", \"Amina\", \"Yusuf\", \"Elena\",\n",
    "    \"Andrew\", \"Bethany\", \"Clara\", \"Derek\", \"Erin\", \"Frank\", \"Gloria\", \"Henry\",\n",
    "    \"Irene\", \"Jack\", \"Kelsey\", \"Leon\", \"Megan\", \"Nathan\", \"Olive\", \"Peter\",\n",
    "    \"Rebecca\", \"Scott\", \"Travis\", \"Ulysses\", \"Vanessa\", \"Wendy\", \"Xavier\",\n",
    "    \"Yvonne\", \"Zeke\", \"Amber\", \"Brett\", \"Colin\", \"Danielle\", \"Elliot\", \"Felix\",\n",
    "    \"Grant\", \"Heidi\", \"Jonah\", \"Kara\", \"Landon\", \"Madeline\", \"Neil\", \"Phoebe\",\n",
    "    \"Riley\", \"Shane\", \"Tiffany\", \"Victor\", \"Walter\", \"Zelda\", \"Miles\", \"Chloe\",\n",
    "    \"Audrey\", \"Spencer\", \"Greta\", \"Dean\", \"Natalie\", \"Brooke\", \"Trent\", \"Hope\",\n",
    "    \"Logan\", \"Seth\", \"Carla\", \"Graham\", \"Melanie\", \"Douglas\", \"April\", \"Connor\",\n",
    "    \"Mallory\", \"Eleanor\", \"Brandon\", \"Joy\", \"Harvey\", \"Celeste\",\n",
    "    \"Anouk\", \"Lorenzo\", \"Ingrid\", \"Marek\", \"Soren\", \"Frida\", \"Rafaël\", \"Katarina\",\n",
    "    \"Tomas\", \"Elsa\", \"Nikolai\", \"Greta\", \"Leandro\", \"Marta\", \"Lucien\", \"Sabine\",\n",
    "    \"Petra\", \"Emil\", \"Renata\", \"Dieter\", \"Alessia\", \"Joaquín\", \"Lukas\", \"Helena\",\n",
    "    \"Isolde\", \"Mateusz\", \"Beatrix\", \"Alban\", \"Nadia\", \"Stefan\", \"Camille\", \"Viktor\",\n",
    "    \"Simone\", \"Astrid\", \"Jens\", \"Florian\", \"Bruno\", \"Agnes\", \"Otto\", \"Liliane\",\n",
    "    \"Pascal\", \"Anastasia\", \"Sergei\", \"Ivana\", \"Karolina\", \"Bjorn\", \"Magdalena\",\n",
    "    \"Casper\", \"Milena\", \"Timo\", \"Leontine\", \"Gregor\", \"Sylvie\", \"Rocco\", \"Noemi\",\n",
    "    \"Dagmar\", \"Cecile\", \"Kristof\", \"Edda\", \"Giulia\", \"Rudolf\", \"Martina\", \"Kamil\",\n",
    "    \"Zuzana\", \"Andrei\", \"Laure\", \"Thibault\", \"Rozalia\", \"Niels\", \"Mireille\",\n",
    "    \"Ashley\", \"Brady\", \"Cody\", \"Dakota\", \"Emily\", \"Garrett\", \"Haley\", \"Jared\",\n",
    "    \"Kayla\", \"Logan\", \"Mason\", \"Natalie\", \"Peyton\", \"Reagan\", \"Savannah\", \"Tanner\",\n",
    "    \"Addison\", \"Brayden\", \"Cassidy\", \"Devon\", \"Emmett\", \"Grayson\", \"Hunter\", \"Jace\",\n",
    "    \"Kaitlyn\", \"Landon\", \"Madison\", \"Noelle\", \"Parker\", \"Ryder\", \"Skylar\", \"Tyler\",\n",
    "    \"Aubrey\", \"Blake\", \"Colton\", \"Delaney\", \"Easton\", \"Faith\", \"Grant\", \"Hope\",\n",
    "    \"Jayden\", \"Kendall\", \"Logan\", \"Morgan\", \"Nevaeh\", \"Preston\", \"Quinton\", \"Riley\",\n",
    "    \"Sierra\", \"Tristan\", \"Wes\", \"Zayden\", \"Bryce\", \"Cheyenne\", \"Dallas\", \"Elle\",\n",
    "    \"Finley\", \"Gage\", \"Harper\", \"Jillian\", \"Kinsley\", \"Lane\", \"Mckenzie\", \"Oakley\",\n",
    "    \"Paxton\", \"Rowan\", \"Sadie\", \"Tucker\", \"Walker\", \"Zion\"\n",
    "]\n",
    "\n",
    "\n",
    "models = [\n",
    "    'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'meta-llama/Llama-3.2-3B',\n",
    "    'meta-llama/Llama-3.1-8B-Instruct',\n",
    "    'meta-llama/Llama-3.1-8B',\n",
    "    'gpt2',\n",
    "    'google/gemma-2-2b',\n",
    "    'google/gemma-2-2b-it',\n",
    "    'Qwen/Qwen3-0.6B',\n",
    "    'Qwen/Qwen3-4B',\n",
    "    # 'google/gemma-3-4b-it'\n",
    "]\n",
    "\n",
    "def filter_names(tokenizer, names):\n",
    "    filtered_names = []\n",
    "    for name in names:\n",
    "        tokenized_name = tokenizer(name, return_tensors='pt', add_special_tokens=False)\n",
    "\n",
    "        if len(tokenized_name['input_ids'][0]) == 1:\n",
    "            filtered_names.append(name)\n",
    "    return filtered_names\n",
    "\n",
    "df = pd.read_csv(\"datasets/old_templates/reasoning_templates.csv\")\n",
    "\n",
    "names = names + df['answer1'].unique().tolist() + df['answer2'].unique().tolist()\n",
    "\n",
    "for model in models:\n",
    "    if model == 'gpt2':\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    # Filter out names that are tokenized as multiple tokens\n",
    "    names = filter_names(tokenizer, names)\n",
    "\n",
    "# Save as csv\n",
    "\n",
    "df = pd.DataFrame(names, columns=['name']).drop_duplicates()\n",
    "\n",
    "\n",
    "df.to_csv(\"datasets/generated/names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e995c12",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# N-way date reasoning\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "# Drop duplicates\n",
    "actions = actions.drop_duplicates()\n",
    "# Filter out actions that contain 'his' or 'her'\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        # (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 28)),\n",
    "        (datetime.datetime(2019, 3, 1), datetime.datetime(2019, 4, 30)),\n",
    "        (datetime.datetime(2019, 5, 1), datetime.datetime(2019, 6, 30)),\n",
    "        (datetime.datetime(2019, 7, 1), datetime.datetime(2019, 8, 31)),\n",
    "        (datetime.datetime(2019, 9, 1), datetime.datetime(2019, 10, 31)),\n",
    "        (datetime.datetime(2019, 11, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "        (datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 31)),\n",
    "        (datetime.datetime(2019, 4, 1), datetime.datetime(2019, 5, 31)),\n",
    "        (datetime.datetime(2019, 6, 1), datetime.datetime(2019, 7, 31)),\n",
    "        (datetime.datetime(2019, 8, 1), datetime.datetime(2019, 9, 30)),\n",
    "        (datetime.datetime(2019, 10, 1), datetime.datetime(2019, 11, 30)),\n",
    "        (datetime.datetime(2019, 12, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \" \".join(contexts) + \" The first person that {action} was\"\n",
    "            context = context.format(action=action)\n",
    "            first_idx = sample['date'].idxmin()\n",
    "            first_date = sample['date'].min()\n",
    "            first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = first_date\n",
    "            row['correct_date_str'] = f\"{ordinal(first_date.day)} of {first_date.strftime('%B')}\"\n",
    "            row['correct_answer'] = first_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cbcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tiblias/miniconda3/envs/time-stuff/lib/python3.12/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_vars.py\", line 622, in change_attr_expression\n",
      "    value = eval(expression, frame.f_globals, frame.f_locals)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1\n",
      "    name    date_cf    date_og                                   context0      Emily 2019-01-17 2019-01-17    Emily {action} on the 17th of January.1     Hunter 2019-02-27 2019-02-27  Hunter {action} on the 27th of February.2      Marco 2019-12-20 2019-12-20   Marco {action} on the 20th of December.3      Jerry 2019-11-29 2019-11-29   Jerry {action} on the 29th of November.4      Scott 2019-03-28 2019-03-28      Scott {action} on the 28th of March...       ...        ...        ...                                       ...994      Ian 2019-11-05 2019-11-05      Ian {action} on the 5th of November.995   Andrew 2019-11-28 2019-11-28  Andrew {action} on the 28th of November.996      Max 2019-11-03 2019-11-03      Max {action} on the 3rd of November.997    Maria 2019-03-20 2019-03-20      Maria {action} on the 20th of March.999  Richard 2019-05-08 2019-05-08       Richard {action} on the 8th of May.[975 rows x 4 columns]\n",
      "                                                                                          ^\n",
      "SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "# N-way date reasoning counterfactual\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "def swap_months(date, month1, month2):\n",
    "    if date.month == month1:\n",
    "        date_og = date.replace(month=month2)\n",
    "    elif date.month == month2:\n",
    "        date_og = date.replace(month=month1)\n",
    "    else:\n",
    "        date_og = date_cf\n",
    "    return date, date_og\n",
    "\n",
    "def format_date_cf(date):\n",
    "    str_date = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    # str_date = str_date.replace('June', 'December').replace('December', 'June')\n",
    "    str_date = str_date.replace('August', 'October').replace('October', 'August')\n",
    "    return str_date\n",
    "\n",
    "def format_date(date):\n",
    "    return f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "# Drop duplicates\n",
    "actions = actions.drop_duplicates()\n",
    "# Filter out actions that contain 'his' or 'her'\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date_cf = min_date + (max_date - min_date) * random.random()\n",
    "    date_cf = date_cf.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_cf, date_og = swap_months(date_cf, 8, 10)  # Swap June and December\n",
    "\n",
    "    date_str = format_date_cf(date_cf)\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date_cf, date_og, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date_cf', 'date_og', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "        # (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 28)),\n",
    "        # (datetime.datetime(2019, 3, 1), datetime.datetime(2019, 4, 30)),\n",
    "        # (datetime.datetime(2019, 5, 1), datetime.datetime(2019, 6, 30)),\n",
    "        # (datetime.datetime(2019, 7, 1), datetime.datetime(2019, 8, 31)),\n",
    "        # (datetime.datetime(2019, 9, 1), datetime.datetime(2019, 10, 31)),\n",
    "        # (datetime.datetime(2019, 11, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "        # (datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 31)),\n",
    "        # (datetime.datetime(2019, 4, 1), datetime.datetime(2019, 5, 31)),\n",
    "        # (datetime.datetime(2019, 6, 1), datetime.datetime(2019, 7, 31)),\n",
    "        # (datetime.datetime(2019, 8, 1), datetime.datetime(2019, 9, 30)),\n",
    "        # (datetime.datetime(2019, 10, 1), datetime.datetime(2019, 11, 30)),\n",
    "        # (datetime.datetime(2019, 12, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date_cf'] >= start_date) & (df_people['date_cf'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date_cf'].nunique() < N or sample['name'].nunique() < N:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \"The following events take place on Earth2, where August and October are swapped. \" + \" \".join(contexts) + \" The first person that {action} was\"\n",
    "            context = context.format(action=action)\n",
    "            first_idx = sample['date_cf'].idxmin()\n",
    "            first_date = sample['date_cf'].min()\n",
    "            first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date_cf'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = first_date\n",
    "            row['correct_date_str'] = format_date_cf(first_date)\n",
    "            row['correct_date_og'] = sample['date_og'].iloc[first_idx]\n",
    "            row['correct_date_og_str'] = format_date(sample['date_og'].iloc[first_idx])\n",
    "            row['correct_answer'] = first_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_cf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1254.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with seasons\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "season_to_label = {\n",
    "    'winter': 0,\n",
    "    'spring': 1,\n",
    "    'summer': 2,\n",
    "    'fall': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "winter_start = datetime.datetime(2019, 12, 21)\n",
    "winter_end = datetime.datetime(2019, 3, 20)\n",
    "spring_start = datetime.datetime(2019, 3, 21)\n",
    "spring_end = datetime.datetime(2019, 6, 20)\n",
    "summer_start = datetime.datetime(2019, 6, 21)\n",
    "summer_end = datetime.datetime(2019, 9, 22)\n",
    "fall_start = datetime.datetime(2019, 9, 23)\n",
    "fall_end = datetime.datetime(2019, 12, 20)\n",
    "\n",
    "seasons = {\n",
    "    'winter': (winter_start, winter_end),\n",
    "    'spring': (spring_start, spring_end),\n",
    "    'summer': (summer_start, summer_end),\n",
    "    'fall': (fall_start, fall_end)\n",
    "}\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    season = None\n",
    "    if date >= winter_start or date <= winter_end:\n",
    "        season = 'winter'\n",
    "    elif date >= spring_start and date <= spring_end:\n",
    "        season = 'spring'\n",
    "    elif date >= summer_start and date <= summer_end:\n",
    "        season = 'summer'\n",
    "    elif date >= fall_start and date <= fall_end:\n",
    "        season = 'fall'\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, season))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'season'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique season\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['season'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique season\n",
    "            unique_season = sample['season'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['season'] == unique_season]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_season = answer_person['season'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_season + \" is\"\n",
    "            \n",
    "            context = \" \".join(contexts) + \" The only person that {action} in {answer_season} is\"\n",
    "            context = context.format(action=action, answer_season=answer_season)\n",
    "\n",
    "\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_date_str'] = f\"{ordinal(answer_date.day)} of {answer_date.strftime('%B')}\"\n",
    "            row['correct_season'] = answer_season\n",
    "            row['correct_season_label'] = season_to_label[answer_season]\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_season.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef6efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1096.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with implicit seasons\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "season_to_label = {\n",
    "    'winter': 0,\n",
    "    'spring': 1,\n",
    "    'summer': 2,\n",
    "    'fall': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "winter_start = datetime.datetime(2019, 12, 21)\n",
    "winter_end = datetime.datetime(2019, 3, 20)\n",
    "spring_start = datetime.datetime(2019, 3, 21)\n",
    "spring_end = datetime.datetime(2019, 6, 20)\n",
    "summer_start = datetime.datetime(2019, 6, 21)\n",
    "summer_end = datetime.datetime(2019, 9, 22)\n",
    "fall_start = datetime.datetime(2019, 9, 23)\n",
    "fall_end = datetime.datetime(2019, 12, 20)\n",
    "\n",
    "seasons = {\n",
    "    'winter': (winter_start, winter_end),\n",
    "    'spring': (spring_start, spring_end),\n",
    "    'summer': (summer_start, summer_end),\n",
    "    'fall': (fall_start, fall_end)\n",
    "}\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    season = None\n",
    "    if date >= winter_start or date <= winter_end:\n",
    "        season = 'winter'\n",
    "    elif date >= spring_start and date <= spring_end:\n",
    "        season = 'spring'\n",
    "    elif date >= summer_start and date <= summer_end:\n",
    "        season = 'summer'\n",
    "    elif date >= fall_start and date <= fall_end:\n",
    "        season = 'fall'\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, season))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'season'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique season\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['season'].nunique() != 2:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique season\n",
    "            unique_season = sample['season'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['season'] == unique_season]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_season = answer_person['season'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_season + \" is\"\n",
    "            \n",
    "            context = \"Take notice of the season these events happened. \" + \" \".join(contexts) + \" Two of them {action} in the same season. The only one that {action} in a different season is\"\n",
    "            context = context.format(action=action, answer_season=answer_season)\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_date_str'] = f\"{ordinal(answer_date.day)} of {answer_date.strftime('%B')}\"\n",
    "            row['correct_season'] = answer_season\n",
    "            row['correct_season_label'] = season_to_label[answer_season]\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_prepend.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785e9ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1233.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with season counterfactuals\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "season_to_label = {\n",
    "    'winter': 0,\n",
    "    'spring': 1,\n",
    "    'summer': 2,\n",
    "    'fall': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "winter_start = datetime.datetime(2019, 12, 21)\n",
    "winter_end = datetime.datetime(2019, 3, 20)\n",
    "spring_start = datetime.datetime(2019, 3, 21)\n",
    "spring_end = datetime.datetime(2019, 6, 20)\n",
    "summer_start = datetime.datetime(2019, 6, 21)\n",
    "summer_end = datetime.datetime(2019, 9, 22)\n",
    "fall_start = datetime.datetime(2019, 9, 23)\n",
    "fall_end = datetime.datetime(2019, 12, 20)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    og_season = None\n",
    "    cf_season = None\n",
    "    if date >= winter_start or date <= winter_end:\n",
    "        og_season = 'winter'\n",
    "        cf_season = 'summer'\n",
    "    elif date >= spring_start and date <= spring_end:\n",
    "        og_season = 'spring'\n",
    "        cf_season = 'fall'\n",
    "    elif date >= summer_start and date <= summer_end:\n",
    "        og_season = 'summer'\n",
    "        cf_season = 'winter'\n",
    "    elif date >= fall_start and date <= fall_end:\n",
    "        og_season = 'fall'\n",
    "        cf_season = 'spring'\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, og_season, cf_season))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'og_season', 'cf_season'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique season\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['cf_season'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique season\n",
    "            unique_season = sample['cf_season'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['cf_season'] == unique_season]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_season = answer_person['cf_season'].iloc[0]\n",
    "            answer_og_season = answer_person['og_season'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_season + \" is\"\n",
    "            \n",
    "            context = \"The following events take place in the southern hemisphere. \" + \" \".join(contexts) + \" The only person that {action} in {answer_season} is\"\n",
    "            context = context.format(action=action, answer_season=answer_season)\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_date_str'] = f\"{ordinal(answer_date.day)} of {answer_date.strftime('%B')}\"\n",
    "            row['correct_season'] = answer_season\n",
    "            row['correct_season_label'] = season_to_label[answer_season]\n",
    "            row['correct_og_season'] = answer_og_season\n",
    "            row['correct_og_season_label'] = season_to_label[answer_og_season]\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_season_cf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1101.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with temperature\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "def classify_temperature(date):\n",
    "    cold_months = [11, 12, 1, 2, 3, 4]\n",
    "    if date.month in cold_months:\n",
    "        return 'cold'\n",
    "    else:\n",
    "        return 'warm'\n",
    "\n",
    "temperature_to_label = {\n",
    "    'cold': 0,\n",
    "    'warm': 1\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    temperature = classify_temperature(date)\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, temperature))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'temperature'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique temperature\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['temperature'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique temperature\n",
    "            unique_temperature = sample['temperature'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['temperature'] == unique_temperature]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_temperature = answer_person['temperature'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_temperature + \" is\"\n",
    "            \n",
    "            context = \" \".join(contexts) + \" The only person that {action} in a {answer_temperature} month is\"\n",
    "            context = context.format(action=action, answer_temperature=answer_temperature)\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_temperature'] = answer_temperature\n",
    "            row['correct_temperature_label'] = temperature_to_label[answer_temperature]\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_temperature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1181.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with months\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    month = date.strftime('%B')\n",
    "\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, month))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'month'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique month\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['month'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique month\n",
    "            unique_month = sample['month'].value_counts().sample(frac=1.0).idxmin()\n",
    "            answer_person = sample[sample['month'] == unique_month]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_month = answer_person['month'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \" \".join(contexts)\n",
    "            context = context + \" The only person that {action} in {answer_month} is\"\n",
    "            context = context.format(action=action, answer_month=answer_month)\n",
    "            \n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_month'] = answer_month\n",
    "            row['correct_month_label'] = answer_date.month - 1\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_month.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b6df1",
   "metadata": {},
   "source": [
    "### Time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n",
      "Date change count: 687\n",
      "Percentage of date change: 0.229\n"
     ]
    }
   ],
   "source": [
    "# Time of day reasoning - actions\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} at {time}.\"\n",
    "time_start = datetime.time(hour=0, minute=0)\n",
    "time_end = datetime.time(hour=23, minute=59)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_time_of_day.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "# Drops actions that contain 'his' or 'her' across actions_present, actions_past\n",
    "actions = actions[~actions['actions_present'].str.contains('his|her', case=False)]\n",
    "actions = actions[~actions['actions_past'].str.contains('his|her', case=False)]\n",
    "actions = actions.values.tolist()\n",
    "\n",
    "# Create a list of all times of day between time_start and time_end with 15 minute intervals\n",
    "times = []\n",
    "for hour in range(time_start.hour, time_end.hour + 1):\n",
    "    for minute in range(0, 60, 15):\n",
    "        if hour == time_start.hour and minute < time_start.minute:\n",
    "            continue\n",
    "        if hour == time_end.hour and minute > time_end.minute:\n",
    "            continue\n",
    "        times.append(datetime.time(hour, minute))\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a time from list\n",
    "    time = random.choice(times)\n",
    "    if time.hour < 10 and time.hour != 0:\n",
    "        time_str = time.strftime(\"%-H:%M\").lower()\n",
    "    else:\n",
    "        time_str = time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "    # Generate the relevant context\n",
    "    context = prompt.format(name=name, time=time_str, action='{action_present}')\n",
    "    df_people.append((name, time, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'time', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_change_count = 0\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        action_present, action_past = random.choice(actions)\n",
    "        date_change_flag = False\n",
    "        # Sample random time in the time_start and time_end range\n",
    "        # sample from any possible value, not just the ones in times\n",
    "        current_time = datetime.time(random.randint(0, 23), random.randint(0, 59))\n",
    "        if current_time.hour < 10 and current_time.hour != 0:\n",
    "            current_time_str = current_time.strftime(\"%-H:%M\").lower()\n",
    "        else:\n",
    "            current_time_str = current_time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "        # Sample random date in the date_start and date_end range\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['time'].nunique() < N or sample['name'].nunique() < N:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \" \".join(contexts) + \" It is now {current_time_str}. The last person who {action_past} is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the {today_date}. The next person to celebrate their birthday is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the 31st of December. The next person to celebrate their birthday is\"\n",
    "        context = context.format(action_present=action_present, action_past=action_past, current_time_str=current_time_str)\n",
    "\n",
    "        # Find the person with the next birthday\n",
    "        next_time = sample[sample['time'] < current_time].sort_values(by='time', ascending=False).head(1)\n",
    "        if next_time.empty:\n",
    "            date_change_count += 1\n",
    "            date_change_flag = True\n",
    "            next_time = sample.sort_values(by='time', ascending=False).head(1)\n",
    "        answer_person = next_time\n",
    "        # answer_idx = answer_person.index[0]\n",
    "        answer_time = answer_person['time'].iloc[0]\n",
    "        answer_name = answer_person['name'].iloc[0]        \n",
    "\n",
    "        row = {}\n",
    "        alternatives = []\n",
    "        for i, (n, d) in enumerate(zip(sample['name'], sample['time'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'time_{i+1}'] = d\n",
    "            alternatives.append(n)\n",
    "        row['context'] = context\n",
    "        row['date_change'] = date_change_flag\n",
    "        row['alternatives'] = alternatives\n",
    "        row['correct_time'] = answer_time\n",
    "        row['correct_time_expr'] = answer_time.strftime(\"%-H:%M\").lower()\n",
    "        # Time diff in minutes\n",
    "        row['correct_time_diff'] = abs(datetime.datetime.combine(datetime.date.today(), answer_time) - datetime.datetime.combine(datetime.date.today(), current_time)).seconds // 60\n",
    "        row['correct_answer'] = answer_name\n",
    "        row['time_idx_start'] = context.find(row['correct_time_expr'])\n",
    "        row['time_idx_end'] = row['time_idx_start'] + len(row['correct_time_expr'])\n",
    "\n",
    "        data.append(row)\n",
    "    print(f\"Date change count: {date_change_count}\")\n",
    "    print(f\"Percentage of date change: {date_change_count/num_samples}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=3000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/time_of_day_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Time of day reasoning - phases\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "def classify_time_of_day(time):\n",
    "    if time.hour < 6:\n",
    "        return 'night'\n",
    "    elif time.hour < 12:\n",
    "        return 'morning'\n",
    "    elif time.hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "\n",
    "phase_to_label = {\n",
    "    'night': 0,\n",
    "    'morning': 1,\n",
    "    'afternoon': 2,\n",
    "    'evening': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} at {time}.\"\n",
    "time_start = datetime.time(hour=0, minute=0)\n",
    "time_end = datetime.time(hour=23, minute=59)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_time_of_day.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "# Drops actions that contain 'his' or 'her' across actions_present, actions_past\n",
    "actions = actions[~actions['actions_present'].str.contains('his|her', case=False)]\n",
    "actions = actions[~actions['actions_past'].str.contains('his|her', case=False)]\n",
    "actions = actions.values.tolist()\n",
    "\n",
    "# Create a list of all times of day between time_start and time_end with 15 minute intervals\n",
    "times = []\n",
    "for hour in range(time_start.hour, time_end.hour + 1):\n",
    "    for minute in range(0, 60, 15):\n",
    "        if hour == time_start.hour and minute < time_start.minute:\n",
    "            continue\n",
    "        if hour == time_end.hour and minute > time_end.minute:\n",
    "            continue\n",
    "        times.append(datetime.time(hour, minute))\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a time from list\n",
    "    time = random.choice(times)\n",
    "    if time.hour < 10 and time.hour != 0:\n",
    "        time_str = time.strftime(\"%-H:%M\").lower()\n",
    "    else:\n",
    "        time_str = time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "    # Classify the phase of the day\n",
    "    phase = classify_time_of_day(time)\n",
    "\n",
    "    # Generate the relevant context\n",
    "    context = prompt.format(name=name, time=time_str, action='{action_present}')\n",
    "    df_people.append((name, time, context, phase))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'time', 'context', 'phase'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_change_count = 0\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        action_present, action_past = random.choice(actions)\n",
    "\n",
    "        # Sample random date in the date_start and date_end range\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['time'].nunique() < N or sample['name'].nunique() < N or sample['phase'].value_counts().min() > 1:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "        # Find the person with the unique phase\n",
    "        unique_phase = sample['phase'].value_counts().idxmin()\n",
    "        answer_person = sample[sample['phase'] == unique_phase]\n",
    "        # answer_idx = answer_person.index[0]\n",
    "        answer_time = answer_person['time'].iloc[0]\n",
    "        answer_name = answer_person['name'].iloc[0]\n",
    "        answer_phase = answer_person['phase'].iloc[0]\n",
    "        answer_phase_label = phase_to_label[answer_phase]\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \" \".join(contexts) + \" The only person that {action_present} in the {answer_phase} is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the {today_date}. The next person to celebrate their birthday is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the 31st of December. The next person to celebrate their birthday is\"\n",
    "        context = context.format(action_present=action_present, action_past=action_past, answer_phase=answer_phase)\n",
    "\n",
    "        row = {}\n",
    "        alternatives = []\n",
    "        for i, (n, d) in enumerate(zip(sample['name'], sample['time'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'time_{i+1}'] = d\n",
    "            alternatives.append(n)\n",
    "        row['context'] = context\n",
    "        row['alternatives'] = alternatives\n",
    "        row['correct_time'] = answer_time\n",
    "        row['correct_time_expr'] = answer_time.strftime(\"%-H:%M\").lower()\n",
    "        row['correct_answer'] = answer_name\n",
    "        row['correct_phase'] = answer_phase\n",
    "        row['correct_phase_label'] = answer_phase_label\n",
    "        row['time_idx_start'] = context.find(row['correct_time_expr'])\n",
    "        row['time_idx_end'] = row['time_idx_start'] + len(row['correct_time_expr'])\n",
    "        \n",
    "        data.append(row)    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/time_of_day_{N}way_phase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9b1c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Time of day reasoning - phases counterfactuals\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "def classify_time_of_day_og(time):\n",
    "    if time.hour < 6:\n",
    "        return 'night'\n",
    "    elif time.hour < 12:\n",
    "        return 'morning'\n",
    "    elif time.hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "    \n",
    "def classify_time_of_day_cf(time):\n",
    "    # Convert time to minutes since midnight for easy comparison\n",
    "    total_minutes = time.hour * 60 + time.minute\n",
    "\n",
    "    # Define time ranges in minutes\n",
    "    night_start = 9 * 60    # 09:00 → 540\n",
    "    night_end = 17 * 60     # 17:00 → 1020\n",
    "\n",
    "    morning_start = 17 * 60             # 1020\n",
    "    afternoon_start = morning_start + 320  # 1020 + 320 = 1340 → 22:20\n",
    "    evening_start = afternoon_start + 320  # 1340 + 320 = 1660 → 03:40 next day (modulo needed)\n",
    "\n",
    "    if night_start <= total_minutes < night_end:\n",
    "        return 'night'\n",
    "    elif morning_start <= total_minutes < afternoon_start:\n",
    "        return 'morning'\n",
    "    elif (afternoon_start <= total_minutes < 1440) or (0 <= total_minutes < (evening_start % 1440)):\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "\n",
    "phase_to_label = {\n",
    "    'night': 0,\n",
    "    'morning': 1,\n",
    "    'afternoon': 2,\n",
    "    'evening': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} at {time}.\"\n",
    "time_start = datetime.time(hour=0, minute=0)\n",
    "time_end = datetime.time(hour=23, minute=59)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_time_of_day.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "# Drops actions that contain 'his' or 'her' across actions_present, actions_past\n",
    "actions = actions[~actions['actions_present'].str.contains('his|her', case=False)]\n",
    "actions = actions[~actions['actions_past'].str.contains('his|her', case=False)]\n",
    "actions = actions.values.tolist()\n",
    "\n",
    "# Create a list of all times of day between time_start and time_end with 15 minute intervals\n",
    "times = []\n",
    "for hour in range(time_start.hour, time_end.hour + 1):\n",
    "    for minute in range(0, 60, 15):\n",
    "        if hour == time_start.hour and minute < time_start.minute:\n",
    "            continue\n",
    "        if hour == time_end.hour and minute > time_end.minute:\n",
    "            continue\n",
    "        times.append(datetime.time(hour, minute))\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a time from list\n",
    "    time = random.choice(times)\n",
    "    if time.hour < 10 and time.hour != 0:\n",
    "        time_str = time.strftime(\"%-H:%M\").lower()\n",
    "    else:\n",
    "        time_str = time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "    # Classify the phase of the day\n",
    "    phase_cf = classify_time_of_day_cf(time)\n",
    "    phase_og = classify_time_of_day_og(time)\n",
    "\n",
    "    # Generate the relevant context\n",
    "    context = prompt.format(name=name, time=time_str, action='{action_present}')\n",
    "    df_people.append((name, time, context, phase_cf, phase_og))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'time', 'context', 'phase_cf', 'phase_og'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_change_count = 0\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        action_present, action_past = random.choice(actions)\n",
    "\n",
    "        # Sample random date in the date_start and date_end range\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['time'].nunique() < N or sample['name'].nunique() < N or sample['phase_cf'].value_counts().min() > 1:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "        # Find the person with the unique phase\n",
    "        unique_phase = sample['phase_cf'].value_counts().idxmin()\n",
    "        answer_person = sample[sample['phase_cf'] == unique_phase]\n",
    "        # answer_idx = answer_person.index[0]\n",
    "        answer_time = answer_person['time'].iloc[0]\n",
    "        answer_name = answer_person['name'].iloc[0]\n",
    "        answer_phase = answer_person['phase_cf'].iloc[0]\n",
    "        answer_phase_og = answer_person['phase_og'].iloc[0]\n",
    "        answer_phase_label = phase_to_label[answer_phase]\n",
    "        answer_phase_og_label = phase_to_label[answer_phase_og]\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \"The following events take place on Earth2, where night occurs from 9:00-17:00 everywhere. \" + \" \".join(contexts) + \" The only person that {action_present} in the {answer_phase} is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the {today_date}. The next person to celebrate their birthday is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the 31st of December. The next person to celebrate their birthday is\"\n",
    "        context = context.format(action_present=action_present, action_past=action_past, answer_phase=answer_phase)\n",
    "\n",
    "        row = {}\n",
    "        alternatives = []\n",
    "        for i, (n, d) in enumerate(zip(sample['name'], sample['time'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'time_{i+1}'] = d\n",
    "            alternatives.append(n)\n",
    "        row['context'] = context\n",
    "        row['alternatives'] = alternatives\n",
    "        row['correct_time'] = answer_time\n",
    "        row['correct_time_expr'] = answer_time.strftime(\"%-H:%M\").lower()\n",
    "        row['correct_answer'] = answer_name\n",
    "        row['correct_phase'] = answer_phase\n",
    "        row['correct_phase_og'] = answer_phase_og\n",
    "        row['correct_phase_label'] = answer_phase_label\n",
    "        row['correct_phase_og_label'] = answer_phase_og_label\n",
    "        row['time_idx_start'] = context.find(row['correct_time_expr'])\n",
    "        row['time_idx_end'] = row['time_idx_start'] + len(row['correct_time_expr'])\n",
    "        \n",
    "        data.append(row)    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/time_of_day_{N}way_phase_cf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043a192",
   "metadata": {},
   "source": [
    "### Duration, periodic, notable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728aea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Duration reasoning sentences\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "N = 3\n",
    "# prompt = \"{name}'s subscription starts on the {date} and lasts for {duration}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_duration.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions['action'].str.contains('his|her', case=False)]\n",
    "\n",
    "duration_days = ['1 day', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days']\n",
    "length_days = [datetime.timedelta(days=1), datetime.timedelta(days=2), datetime.timedelta(days=3),\n",
    "               datetime.timedelta(days=4), datetime.timedelta(days=5), datetime.timedelta(days=6),\n",
    "               datetime.timedelta(days=7), datetime.timedelta(days=8), datetime.timedelta(days=9), datetime.timedelta(days=10)]\n",
    "duration_weeks = ['1 week', '2 weeks', '3 weeks', '4 weeks',\n",
    "                  '7 days', '10 days', '14 days', '21 days', '25 days', '30 days']\n",
    "length_weeks = [datetime.timedelta(weeks=1), datetime.timedelta(weeks=2), datetime.timedelta(weeks=3), datetime.timedelta(weeks=4),\n",
    "                    datetime.timedelta(days=7), datetime.timedelta(days=10), datetime.timedelta(days=14),\n",
    "                    datetime.timedelta(days=21), datetime.timedelta(days=25), datetime.timedelta(days=30)]\n",
    "duration_months = ['1 month', '2 months', '3 months', '4 months', '6 months', '8 months',\n",
    "                    '4 weeks', '6 weeks', '8 weeks', '10 weeks']\n",
    "length_months = [datetime.timedelta(days=30), datetime.timedelta(days=30*2), datetime.timedelta(days=30*3), datetime.timedelta(days=30*4),\n",
    "                    datetime.timedelta(days=30*6), datetime.timedelta(days=30*8),\n",
    "                    datetime.timedelta(weeks=4), datetime.timedelta(weeks=6), datetime.timedelta(weeks=8), datetime.timedelta(weeks=10)]\n",
    "duration_years = ['1 year', '2 years', '3 years', '4 years',\n",
    "                  '12 months', '18 months', '24 months', '36 months']\n",
    "length_years = [datetime.timedelta(days=365), datetime.timedelta(days=365*2), datetime.timedelta(days=365*3), datetime.timedelta(days=365*4),\n",
    "                    datetime.timedelta(days=30*12), datetime.timedelta(days=30*18), datetime.timedelta(days=30*24), datetime.timedelta(days=30*36)]\n",
    "\n",
    "# Sample (names, date, duration, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "\n",
    "    # Sample a duration type\n",
    "    duration_type, durations, durations_str = random.choice([('days',length_days, duration_days),\n",
    "                                                ('weeks', length_weeks, duration_weeks),\n",
    "                                                ('months', length_months, duration_months),\n",
    "                                                ('years', length_years, duration_years)])\n",
    "    # Sample a duration\n",
    "    idx_duration = random.randint(0, len(durations)-1)\n",
    "    duration = durations[idx_duration]\n",
    "    duration_str = durations_str[idx_duration]\n",
    "    duration_length = duration.days\n",
    "\n",
    "    # Compute the corresponding end date\n",
    "    # NB: this is only approximate, as it does not take into account leap years or month lengths\n",
    "    end_date = date + duration\n",
    "\n",
    "    # Generate the relevant context\n",
    "    # context = prompt.format(name=name, date=date_str, duration=duration_str, action='{action}')\n",
    "    df_people.append((name, date, end_date, duration, duration_str, duration_length, duration_type))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'end_date', 'duration', 'duration_str', 'duration_length', 'duration_type'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        # (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 28)),\n",
    "        (datetime.datetime(2019, 3, 1), datetime.datetime(2019, 4, 30)),\n",
    "        (datetime.datetime(2019, 5, 1), datetime.datetime(2019, 6, 30)),\n",
    "        (datetime.datetime(2019, 7, 1), datetime.datetime(2019, 8, 31)),\n",
    "        (datetime.datetime(2019, 9, 1), datetime.datetime(2019, 10, 31)),\n",
    "        (datetime.datetime(2019, 11, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "        (datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 31)),\n",
    "        (datetime.datetime(2019, 4, 1), datetime.datetime(2019, 5, 31)),\n",
    "        (datetime.datetime(2019, 6, 1), datetime.datetime(2019, 7, 31)),\n",
    "        (datetime.datetime(2019, 8, 1), datetime.datetime(2019, 9, 30)),\n",
    "        (datetime.datetime(2019, 10, 1), datetime.datetime(2019, 11, 30)),\n",
    "        (datetime.datetime(2019, 12, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "\n",
    "            # Sample random date in the date_start and date_end range\n",
    "            # target_date = date_start + datetime.timedelta(days=random.randint(0, 364))\n",
    "\n",
    "\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['duration_type'].nunique() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            \n",
    "            duration_type = sample['duration_type'].iloc[0]\n",
    "\n",
    "            # Sample a random action compatible with the duration type\n",
    "            action = actions.sample()\n",
    "            while action[duration_type].item() is False:\n",
    "                action = actions.sample()\n",
    "\n",
    "            context = action['action'].item()\n",
    "            contexts = [context.format(name=s['name'], date=f\"{ordinal(s['date'].day)} of {s['date'].strftime('%B')}\", \n",
    "                                       duration=s['duration_str'], action='{action}') for i, s in sample.iterrows()]\n",
    "            context = \" \".join(contexts) + f\" The person whose {action['activity'].item()} ends first is\"\n",
    "\n",
    "            answer_person = sample.sort_values(by='end_date').head(1).iloc[0]\n",
    "            answer_date = answer_person['date']\n",
    "            answer_end_date = answer_person['end_date']\n",
    "            answer_duration = answer_person['duration']\n",
    "            answer_duration_str = answer_person['duration_str']\n",
    "            answer_duration_length = answer_person['duration_length']\n",
    "            answer_name = answer_person['name']\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d, dur_str) in enumerate(zip(sample['name'], sample['date'], sample['duration_str'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                row[f'duration_str_{i+1}'] = dur_str\n",
    "            row['context'] = context\n",
    "            row['duration_type'] = duration_type\n",
    "            # row['year_change'] = False if min_col == 'diff' else True\n",
    "            # row['distance'] = answer_person[min_col].days\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_date_expr'] = f\"the {ordinal(answer_date.day)} of {answer_date.strftime('%B')}\"\n",
    "            row['correct_end_date'] = answer_end_date\n",
    "            row['correct_duration'] = answer_duration\n",
    "            row['correct_duration_str'] = answer_duration_str\n",
    "            row['correct_duration_length'] = answer_duration_length\n",
    "            row['correct_month'] = answer_date.strftime('%B')\n",
    "            row['correct_answer'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    data = pd.DataFrame(data)\n",
    "    # print(f\"Year change count: {data['year_change'].sum()}\")\n",
    "    # print(f\"Percentage of year change: {data['year_change'].sum()/num_samples}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=3000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/duration_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f45f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Periodic reasoning sentences\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "N = 3\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_periodic.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions['action'].str.contains('his|her', case=False)]\n",
    "\n",
    "# NOTE: Consider adding other standard durations like 'every weekend', 'every Christmas', 'every New Year', etc. \n",
    "\n",
    "str_days = ['daily', 'every day', 'every other day', 'every 3 days', 'every 4 days', 'every 5 days', 'every 6 days', 'every week',\n",
    "            'twice a week', 'three times a week', 'four times a week', 'five times a week', 'six times a week']\n",
    "period_days = [1, 1, 2, 3, 4, 5, 6, 7, 7/2, 7/3, 7/4, 7/5, 7/6]\n",
    "str_weeks = ['every week', 'every other week', 'every 3 weeks', 'every 4 weeks', 'every 5 weeks', 'every 6 weeks',\n",
    "            'every month', 'twice a month', 'three times a month', 'four times a month', 'five times a month', 'six times a month']             \n",
    "period_weeks = [7, 14, 21, 28, 35, 42, 30, 30/2, 30/3, 30/4, 30/5, 30/6]\n",
    "str_months = ['monthly', 'every other month', 'every two months', 'every 3 months', 'every 4 months', 'every 5 months', 'every 6 months',\n",
    "            'every year', 'twice a year', 'three times a year', 'four times a year', 'five times a year', 'six times a year']\n",
    "period_months = [30, 60, 60, 90, 120, 150, 180, 365, 365/2, 365/3, 365/4, 365/5, 365/6]\n",
    "str_years = ['every year', 'every two years', 'every other year', 'every 3 years', 'every 4 years', 'every 5 years', 'every 6 years']\n",
    "period_years = [365, 730, 365, 1095, 1460, 1825, 2190] \n",
    "\n",
    "# Sample (names, date, period, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "\n",
    "    # Sample a period type\n",
    "    period_type, periods, period_str = random.choice([('days',period_days, str_days),\n",
    "                                                ('weeks', period_weeks, str_weeks),\n",
    "                                                ('months', period_months, str_months),\n",
    "                                                ('years', period_years, str_years)])\n",
    "    # Sample a period\n",
    "    idx_period = random.randint(0, len(periods)-1)\n",
    "    period_str = period_str[idx_period]\n",
    "    period_length = periods[idx_period]\n",
    "\n",
    "    df_people.append((name, period_str, period_length, period_type))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'period_str', 'period_length', 'period_type'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    data = []\n",
    "    # Filter the dataframe to get people born in the date range\n",
    "    for _ in range(num_samples):\n",
    "\n",
    "        # NOTE: Try also sampling multiple period_types and their compatible actions\n",
    "\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['period_length'].nunique() < N or sample['name'].nunique() < N or sample['period_type'].nunique() > 1:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        \n",
    "        period_type = sample['period_type'].iloc[0]\n",
    "\n",
    "        # Sample a random action compatible with the period type\n",
    "        action = actions.sample()\n",
    "        while action[period_type].item() is False:\n",
    "            action = actions.sample()\n",
    "\n",
    "        context = action['action'].item()\n",
    "        contexts = [context.format(name=s['name'], frequency=s['period_str']) for i, s in sample.iterrows()]\n",
    "        context = \" \".join(contexts) + f\" The person who {action['activity'].item()} more often is\"\n",
    "\n",
    "        answer_person = sample.sort_values(by='period_length', ascending=True).iloc[0]\n",
    "        answer_period_str = answer_person['period_str']\n",
    "        answer_period_length = answer_person['period_length']\n",
    "        answer_name = answer_person['name']\n",
    "\n",
    "        row = {}\n",
    "        for i, (n, d, dur_str) in enumerate(zip(sample['name'], sample['period_length'], sample['period_str'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'period_length_{i+1}'] = d\n",
    "            row[f'period_str_{i+1}'] = dur_str\n",
    "        row['context'] = context\n",
    "        row['period_type'] = period_type\n",
    "        row['correct_period_str'] = answer_period_str\n",
    "        row['correct_period_length'] = answer_period_length\n",
    "        row['correct_answer'] = answer_name\n",
    "\n",
    "        data.append(row)\n",
    "    data = pd.DataFrame(data)\n",
    "    # print(f\"Year change count: {data['year_change'].sum()}\")\n",
    "    # print(f\"Percentage of year change: {data['year_change'].sum()/num_samples}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=4000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/periodic_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6671554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Notable year reasoning\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "N = 3\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "events = pd.read_csv(\"datasets/generated/timeline_paraphrased.csv\")\n",
    "events['date'] = pd.to_datetime(events['date'], errors='coerce')\n",
    "events = events.drop_duplicates()\n",
    "min_date = events['date'].min()\n",
    "max_date = events['date'].max()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    event = events.sample()\n",
    "    # Sample a date\n",
    "    date = event['date'].item()\n",
    "    # Sample a context\n",
    "    context = event['event'].item().format(name=name)\n",
    "    df_people.append((name, date, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    # Every decade from 1900 to 2000\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(year, 1, 1), datetime.datetime(year + 19, 12, 31)) for year in range(1900, 2000, 10)\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \" \".join(contexts) + \" The oldest is\"\n",
    "            first_idx = sample['date'].idxmin()\n",
    "            first_date = sample['date'].min()\n",
    "            first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = first_date\n",
    "            row['correct_answer'] = first_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/notable_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602592b1",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b78e5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Earth coordinates reasoning\n",
    "# Uses https://simplemaps.com/data/world-cities\n",
    "\n",
    "# Template: Anna lives in Paris. [...] The person who lives closest to Anna is\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fill_missing_continents(cities: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fill missing 'continent' values using majority vote of the 3 nearest cities by (lat, lon) distance.\n",
    "\n",
    "    Args:\n",
    "        cities (pd.DataFrame): DataFrame with 'lat', 'lng', and 'continent' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing 'continent' values filled.\n",
    "    \"\"\"\n",
    "    # Separate known and unknown continent rows\n",
    "    known = cities.dropna(subset=['continent']).copy()\n",
    "    unknown = cities[cities['continent'].isna()].copy()\n",
    "\n",
    "    if unknown.empty:\n",
    "        return cities  # nothing to fill\n",
    "\n",
    "    # Build KD-tree on known lat/lng\n",
    "    tree = cKDTree(known[['lat', 'lng']].values)\n",
    "\n",
    "    # Query 3 nearest neighbors for each unknown city\n",
    "    distances, indices = tree.query(unknown[['lat', 'lng']].values, k=3)\n",
    "\n",
    "    # Assign continent by majority vote\n",
    "    inferred_continents = []\n",
    "    for idx_group in indices:\n",
    "        neighbors = known.iloc[idx_group]\n",
    "        continent_votes = neighbors['continent']\n",
    "        most_common = Counter(continent_votes).most_common(1)[0][0]\n",
    "        inferred_continents.append(most_common)\n",
    "\n",
    "    # Assign back to DataFrame\n",
    "    cities.loc[unknown.index, 'continent'] = inferred_continents\n",
    "\n",
    "    return cities\n",
    "\n",
    "\n",
    "def sample_cities(cities: pd.DataFrame, n_per_bin: int = 10, lat_bins: int = 18, lon_bins: int = 36) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evenly sample cities across latitude and longitude space.\n",
    "    \"\"\"\n",
    "    # Ensure valid coordinates\n",
    "    cities = cities.dropna(subset=['lat', 'lng'])\n",
    "\n",
    "    # Create bins for latitude and longitude\n",
    "    cities['lat_bin'] = pd.cut(cities['lat'], bins=lat_bins)\n",
    "    cities['lon_bin'] = pd.cut(cities['lng'], bins=lon_bins)\n",
    "\n",
    "    # Sort by population and sample one city per bin (most populous)\n",
    "    sampled = (\n",
    "        cities\n",
    "        .sort_values('population', ascending=False)\n",
    "        .groupby(['lat_bin', 'lon_bin'], group_keys=False)\n",
    "        .sample(n_per_bin, random_state=42, replace=True)\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return sampled\n",
    "\n",
    "def euclidean_distance(lat1, lon1, lat2, lon2):\n",
    "    # Treat (lat, lon) as 2D Cartesian points in degrees\n",
    "    p1 = np.array([lat1, lon1])\n",
    "    p2 = np.array([lat2, lon2])\n",
    "    \n",
    "    return np.linalg.norm(p2 - p1)\n",
    "\n",
    "def through_earth_distance(lat1, lon1, lat2, lon2, radius=6371):\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad, lon1_rad = np.radians([lat1, lon1])\n",
    "    lat2_rad, lon2_rad = np.radians([lat2, lon2])\n",
    "\n",
    "    # Cartesian coordinates for both points\n",
    "    def to_cartesian(lat, lon):\n",
    "        x = radius * np.cos(lat) * np.cos(lon)\n",
    "        y = radius * np.cos(lat) * np.sin(lon)\n",
    "        z = radius * np.sin(lat)\n",
    "        return np.array([x, y, z])\n",
    "\n",
    "    p1 = to_cartesian(lat1_rad, lon1_rad)\n",
    "    p2 = to_cartesian(lat2_rad, lon2_rad)\n",
    "\n",
    "    # Euclidean (through-the-Earth) distance\n",
    "    return np.linalg.norm(p2 - p1)\n",
    "\n",
    "def geodesic_distance(lat1, lon1, lat2, lon2, radius=6371):\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad, lon1_rad = np.radians([lat1, lon1])\n",
    "    lat2_rad, lon2_rad = np.radians([lat2, lon2])\n",
    "    \n",
    "    # Differences\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Distance\n",
    "    return radius * c\n",
    "\n",
    "def sample_people(df_people, N):\n",
    "    sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "    first_idx = sample.index[0]\n",
    "    first_city = sample['city'].iloc[first_idx]\n",
    "    first_lat = sample['lat'].iloc[first_idx]\n",
    "    first_lon = sample['lon'].iloc[first_idx]\n",
    "    first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "    sample['euclidean_dist'] = sample.apply(\n",
    "        lambda row: euclidean_distance(first_lat, first_lon, row['lat'], row['lon']), axis=1)\n",
    "    sample['through_earth_dist'] = sample.apply(\n",
    "        lambda row: through_earth_distance(first_lat, first_lon, row['lat'], row['lon']), axis=1)\n",
    "    sample['geodesic_dist'] = sample.apply(\n",
    "        lambda row: geodesic_distance(first_lat, first_lon, row['lat'], row['lon']), axis=1)\n",
    "    \n",
    "    # Exclude the first person from the distance calculations\n",
    "    sample_remaining = sample.drop(index=first_idx).reset_index(drop=True)\n",
    "\n",
    "    closest_geodesic = sample_remaining['geodesic_dist'].idxmin()\n",
    "    closest_through_earth = sample_remaining['through_earth_dist'].idxmin()\n",
    "    closest_euclidean = sample_remaining['euclidean_dist'].idxmin()\n",
    "    is_same = closest_geodesic == closest_through_earth == closest_euclidean\n",
    "    return sample, is_same\n",
    "\n",
    "def sample_valid_people(df_people, N):\n",
    "    sample, is_same = sample_people(df_people, N)\n",
    "    while sample['city'].nunique() < N or sample['name'].nunique() < N or not is_same:\n",
    "        sample, is_same = sample_people(df_people, N)\n",
    "    return sample\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} lives in {city}.\"\n",
    "\n",
    "names = pd.read_csv(\"datasets/generated/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "# Load and filter the dataset\n",
    "cities = pd.read_csv(\"datasets/sourced/worldcities.csv\")\n",
    "cities = cities[\n",
    "    (cities['capital'].isin(['primary', 'admin', 'minor'])) |\n",
    "    ((cities['country'].isin(['United States', 'Canada'])) & (cities['population'] > 100000))\n",
    "].reset_index(drop=True)\n",
    "\n",
    "continents = pd.read_csv(\"datasets/sourced/countries_by_continent.csv\")\n",
    "cities = cities.merge(continents, on='country', how='left')\n",
    "cities = fill_missing_continents(cities)\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(10000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a city\n",
    "    city = cities.sample()\n",
    "    city_name = city['city'].item()\n",
    "    lat = city['lat'].item()\n",
    "    lon = city['lng'].item()\n",
    "    country = city['country'].item()\n",
    "    continent = city['continent'].item()\n",
    "\n",
    "    # Generate the context\n",
    "    context = prompt.format(name=name, city=city_name)\n",
    "    df_people.append((name, city_name, country, lat, lon, continent, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'city', 'country', 'lat', 'lon', 'continent', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):    \n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        sample = sample_valid_people(df_people, N)\n",
    "        first_idx = sample.index[0]\n",
    "        first_city = sample['city'].iloc[first_idx]\n",
    "        first_country = sample['country'].iloc[first_idx]\n",
    "        first_lat = sample['lat'].iloc[first_idx]\n",
    "        first_lon = sample['lon'].iloc[first_idx]\n",
    "        first_continent = sample['continent'].iloc[first_idx]\n",
    "        first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \" \".join(contexts) + f\" The person who lives closest to {first_name} is\"\n",
    "        \n",
    "        answer_idx = sample[1:]['geodesic_dist'].idxmin()\n",
    "        answer_city = sample['city'].iloc[answer_idx]\n",
    "        answer_country = sample['country'].iloc[answer_idx]\n",
    "        answer_lat = sample['lat'].iloc[answer_idx]\n",
    "        answer_lon = sample['lon'].iloc[answer_idx]\n",
    "        answer_continent = sample['continent'].iloc[answer_idx]\n",
    "        answer_name = sample['name'].iloc[answer_idx]\n",
    "        answer_geodesic_dist = sample['geodesic_dist'].iloc[answer_idx]\n",
    "        answer_through_earth_dist = sample['through_earth_dist'].iloc[answer_idx]\n",
    "        answer_euclidean_dist = sample['euclidean_dist'].iloc[answer_idx]\n",
    "\n",
    "        row = {}\n",
    "        row['context'] = context\n",
    "        row['correct_city'] = answer_city\n",
    "        row['correct_country'] = answer_country\n",
    "        row['correct_continent'] = answer_continent\n",
    "        row['correct_lat'] = answer_lat\n",
    "        row['correct_lon'] = answer_lon\n",
    "        row['correct_geodesic_dist'] = answer_geodesic_dist\n",
    "        row['correct_through_earth_dist'] = answer_through_earth_dist\n",
    "        row['correct_euclidean_dist'] = answer_euclidean_dist\n",
    "        row['correct_answer'] = answer_name                                                    \n",
    "        row['reference_city'] = first_city\n",
    "        row['reference_country'] = first_country\n",
    "        row['reference_continent'] = first_continent\n",
    "        row['reference_lat'] = first_lat\n",
    "        row['reference_lon'] = first_lon\n",
    "        row['reference_name'] = first_name\n",
    "        for i, (n, ct, cn, cnt, lt, ln) in enumerate(zip(sample['name'], sample['city'], sample['country'], sample['continent'], sample['lat'], sample['lon'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'city_{i+1}'] = ct\n",
    "            row[f'country_{i+1}'] = cn\n",
    "            row[f'continent_{i+1}'] = cnt\n",
    "            row[f'lat_{i+1}'] = lt\n",
    "            row[f'lon_{i+1}'] = ln\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=2000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/cities_{N}way.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
