{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name list generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, GPT2Tokenizer\n",
    "\n",
    "names = [\n",
    "    \"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Ethan\", \"Fiona\", \"George\", \"Hannah\",\n",
    "    \"Isaac\", \"Julia\", \"Kevin\", \"Laura\", \"Michael\", \"Nina\", \"Oliver\", \"Paula\",\n",
    "    \"Quentin\", \"Rachel\", \"Samuel\", \"Tina\", \"Umar\", \"Vera\", \"William\", \"Xena\",\n",
    "    \"Yusuf\", \"Zara\", \"Aaron\", \"Bianca\", \"Caleb\", \"Denise\", \"Elijah\", \"Faith\",\n",
    "    \"Gavin\", \"Hailey\", \"Ian\", \"Jasmine\", \"Kyle\", \"Lena\", \"Martin\", \"Nora\",\n",
    "    \"Owen\", \"Penelope\", \"Quinn\", \"Rose\", \"Sebastian\", \"Talia\", \"Uri\", \"Valerie\",\n",
    "    \"Wesley\", \"Xander\", \"Yara\", \"Zane\", \"Amira\", \"Diego\", \"Liam\", \"Noah\",\n",
    "    \"Sofia\", \"Mateo\", \"Aaliyah\", \"Levi\", \"Mohammed\", \"Priya\", \"Jorge\", \"Akira\",\n",
    "    \"Fatima\", \"Chang\", \"Layla\", \"Anika\", \"Raj\", \"Mei\", \"Imani\", \"Kenji\",\n",
    "    \"Adriana\", \"Santiago\", \"Lucia\", \"Mila\", \"Khalid\", \"Jin\", \"Zane\", \"Sasha\",\n",
    "    \"Giovanni\", \"Ines\", \"Tariq\", \"Naomi\", \"Reza\", \"Lina\", \"Omar\", \"Tanvi\",\n",
    "    \"Marco\", \"Soraya\", \"Arjun\", \"Dmitri\", \"Salma\", \"Thiago\", \"Yuna\", \"Niko\",\n",
    "    \"Carmen\", \"Ishaan\", \"Aliyah\", \"Hiro\", \"Luca\", \"Samira\", \"Fernando\", \"Alina\",\n",
    "    \"Dalia\", \"Ravi\", \"Zara\", \"Emilio\", \"Kira\", \"Amina\", \"Yusuf\", \"Elena\",\n",
    "    \"Andrew\", \"Bethany\", \"Clara\", \"Derek\", \"Erin\", \"Frank\", \"Gloria\", \"Henry\",\n",
    "    \"Irene\", \"Jack\", \"Kelsey\", \"Leon\", \"Megan\", \"Nathan\", \"Olive\", \"Peter\",\n",
    "    \"Rebecca\", \"Scott\", \"Travis\", \"Ulysses\", \"Vanessa\", \"Wendy\", \"Xavier\",\n",
    "    \"Yvonne\", \"Zeke\", \"Amber\", \"Brett\", \"Colin\", \"Danielle\", \"Elliot\", \"Felix\",\n",
    "    \"Grant\", \"Heidi\", \"Jonah\", \"Kara\", \"Landon\", \"Madeline\", \"Neil\", \"Phoebe\",\n",
    "    \"Riley\", \"Shane\", \"Tiffany\", \"Victor\", \"Walter\", \"Zelda\", \"Miles\", \"Chloe\",\n",
    "    \"Audrey\", \"Spencer\", \"Greta\", \"Dean\", \"Natalie\", \"Brooke\", \"Trent\", \"Hope\",\n",
    "    \"Logan\", \"Seth\", \"Carla\", \"Graham\", \"Melanie\", \"Douglas\", \"April\", \"Connor\",\n",
    "    \"Mallory\", \"Eleanor\", \"Brandon\", \"Joy\", \"Harvey\", \"Celeste\",\n",
    "    \"Anouk\", \"Lorenzo\", \"Ingrid\", \"Marek\", \"Soren\", \"Frida\", \"Rafaël\", \"Katarina\",\n",
    "    \"Tomas\", \"Elsa\", \"Nikolai\", \"Greta\", \"Leandro\", \"Marta\", \"Lucien\", \"Sabine\",\n",
    "    \"Petra\", \"Emil\", \"Renata\", \"Dieter\", \"Alessia\", \"Joaquín\", \"Lukas\", \"Helena\",\n",
    "    \"Isolde\", \"Mateusz\", \"Beatrix\", \"Alban\", \"Nadia\", \"Stefan\", \"Camille\", \"Viktor\",\n",
    "    \"Simone\", \"Astrid\", \"Jens\", \"Florian\", \"Bruno\", \"Agnes\", \"Otto\", \"Liliane\",\n",
    "    \"Pascal\", \"Anastasia\", \"Sergei\", \"Ivana\", \"Karolina\", \"Bjorn\", \"Magdalena\",\n",
    "    \"Casper\", \"Milena\", \"Timo\", \"Leontine\", \"Gregor\", \"Sylvie\", \"Rocco\", \"Noemi\",\n",
    "    \"Dagmar\", \"Cecile\", \"Kristof\", \"Edda\", \"Giulia\", \"Rudolf\", \"Martina\", \"Kamil\",\n",
    "    \"Zuzana\", \"Andrei\", \"Laure\", \"Thibault\", \"Rozalia\", \"Niels\", \"Mireille\",\n",
    "    \"Ashley\", \"Brady\", \"Cody\", \"Dakota\", \"Emily\", \"Garrett\", \"Haley\", \"Jared\",\n",
    "    \"Kayla\", \"Logan\", \"Mason\", \"Natalie\", \"Peyton\", \"Reagan\", \"Savannah\", \"Tanner\",\n",
    "    \"Addison\", \"Brayden\", \"Cassidy\", \"Devon\", \"Emmett\", \"Grayson\", \"Hunter\", \"Jace\",\n",
    "    \"Kaitlyn\", \"Landon\", \"Madison\", \"Noelle\", \"Parker\", \"Ryder\", \"Skylar\", \"Tyler\",\n",
    "    \"Aubrey\", \"Blake\", \"Colton\", \"Delaney\", \"Easton\", \"Faith\", \"Grant\", \"Hope\",\n",
    "    \"Jayden\", \"Kendall\", \"Logan\", \"Morgan\", \"Nevaeh\", \"Preston\", \"Quinton\", \"Riley\",\n",
    "    \"Sierra\", \"Tristan\", \"Wes\", \"Zayden\", \"Bryce\", \"Cheyenne\", \"Dallas\", \"Elle\",\n",
    "    \"Finley\", \"Gage\", \"Harper\", \"Jillian\", \"Kinsley\", \"Lane\", \"Mckenzie\", \"Oakley\",\n",
    "    \"Paxton\", \"Rowan\", \"Sadie\", \"Tucker\", \"Walker\", \"Zion\"\n",
    "]\n",
    "\n",
    "\n",
    "models = [\n",
    "    'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'meta-llama/Llama-3.2-3B',\n",
    "    'meta-llama/Llama-3.1-8B-Instruct',\n",
    "    'meta-llama/Llama-3.1-8B',\n",
    "    'gpt2',\n",
    "    'google/gemma-2-2b',\n",
    "    'google/gemma-2-2b-it',\n",
    "    'Qwen/Qwen3-0.6B',\n",
    "    'Qwen/Qwen3-4B',\n",
    "    # 'google/gemma-3-4b-it'\n",
    "]\n",
    "\n",
    "def filter_names(tokenizer, names):\n",
    "    filtered_names = []\n",
    "    for name in names:\n",
    "        tokenized_name = tokenizer(name, return_tensors='pt', add_special_tokens=False)\n",
    "\n",
    "        if len(tokenized_name['input_ids'][0]) == 1:\n",
    "            filtered_names.append(name)\n",
    "    return filtered_names\n",
    "\n",
    "df = pd.read_csv(\"datasets/templates/reasoning_templates.csv\")\n",
    "\n",
    "names = names + df['answer1'].unique().tolist() + df['answer2'].unique().tolist()\n",
    "\n",
    "for model in models:\n",
    "    if model == 'gpt2':\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    # Filter out names that are tokenized as multiple tokens\n",
    "    names = filter_names(tokenizer, names)\n",
    "\n",
    "# Save as csv\n",
    "\n",
    "df = pd.DataFrame(names, columns=['name']).drop_duplicates()\n",
    "\n",
    "\n",
    "df.to_csv(\"datasets/templates/names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# N-way date reasoning\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "# Drop duplicates\n",
    "actions = actions.drop_duplicates()\n",
    "# Filter out actions that contain 'his' or 'her'\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        # (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 28)),\n",
    "        (datetime.datetime(2019, 3, 1), datetime.datetime(2019, 4, 30)),\n",
    "        (datetime.datetime(2019, 5, 1), datetime.datetime(2019, 6, 30)),\n",
    "        (datetime.datetime(2019, 7, 1), datetime.datetime(2019, 8, 31)),\n",
    "        (datetime.datetime(2019, 9, 1), datetime.datetime(2019, 10, 31)),\n",
    "        (datetime.datetime(2019, 11, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "        (datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 31)),\n",
    "        (datetime.datetime(2019, 4, 1), datetime.datetime(2019, 5, 31)),\n",
    "        (datetime.datetime(2019, 6, 1), datetime.datetime(2019, 7, 31)),\n",
    "        (datetime.datetime(2019, 8, 1), datetime.datetime(2019, 9, 30)),\n",
    "        (datetime.datetime(2019, 10, 1), datetime.datetime(2019, 11, 30)),\n",
    "        (datetime.datetime(2019, 12, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \" \".join(contexts) + \" The first person that {action} was\"\n",
    "            context = context.format(action=action)\n",
    "            first_idx = sample['date'].idxmin()\n",
    "            first_date = sample['date'].min()\n",
    "            first_name = sample['name'].iloc[first_idx]\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = first_date\n",
    "            row['correct'] = first_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1170.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with seasons\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "season_to_label = {\n",
    "    'winter': 0,\n",
    "    'spring': 1,\n",
    "    'summer': 2,\n",
    "    'fall': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "winter_start = datetime.datetime(2019, 12, 21)\n",
    "winter_end = datetime.datetime(2019, 3, 20)\n",
    "spring_start = datetime.datetime(2019, 3, 21)\n",
    "spring_end = datetime.datetime(2019, 6, 20)\n",
    "summer_start = datetime.datetime(2019, 6, 21)\n",
    "summer_end = datetime.datetime(2019, 9, 22)\n",
    "fall_start = datetime.datetime(2019, 9, 23)\n",
    "fall_end = datetime.datetime(2019, 12, 20)\n",
    "\n",
    "seasons = {\n",
    "    'winter': (winter_start, winter_end),\n",
    "    'spring': (spring_start, spring_end),\n",
    "    'summer': (summer_start, summer_end),\n",
    "    'fall': (fall_start, fall_end)\n",
    "}\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    season = None\n",
    "    if date >= winter_start or date <= winter_end:\n",
    "        season = 'winter'\n",
    "    elif date >= spring_start and date <= spring_end:\n",
    "        season = 'spring'\n",
    "    elif date >= summer_start and date <= summer_end:\n",
    "        season = 'summer'\n",
    "    elif date >= fall_start and date <= fall_end:\n",
    "        season = 'fall'\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, season))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'season'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique season\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['season'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique season\n",
    "            unique_season = sample['season'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['season'] == unique_season]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_season = answer_person['season'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_season + \" is\"\n",
    "            \n",
    "            context = \" \".join(contexts) + \" The only person that {action} in {answer_season} is\"\n",
    "            context = context.format(action=action, answer_season=answer_season)\n",
    "\n",
    "\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_season'] = answer_season\n",
    "            row['correct_season_label'] = season_to_label[answer_season]\n",
    "            row['correct'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_season.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1030.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with temperature\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "def classify_temperature(date):\n",
    "    cold_months = [11, 12, 1, 2, 3, 4]\n",
    "    if date.month in cold_months:\n",
    "        return 'cold'\n",
    "    else:\n",
    "        return 'warm'\n",
    "\n",
    "temperature_to_label = {\n",
    "    'cold': 0,\n",
    "    'warm': 1\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    temperature = classify_temperature(date)\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, temperature))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'temperature'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique temperature\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['temperature'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique temperature\n",
    "            unique_temperature = sample['temperature'].value_counts().idxmin()\n",
    "            answer_person = sample[sample['temperature'] == unique_temperature]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_temperature = answer_person['temperature'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            # context = \" \".join(contexts) + \" The only person born in \" + answer_temperature + \" is\"\n",
    "            \n",
    "            context = \" \".join(contexts) + \" The only person that {action} in a {answer_temperature} month is\"\n",
    "            context = context.format(action=action, answer_temperature=answer_temperature)\n",
    "\n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_temperature'] = answer_temperature\n",
    "            row['correct_temperature_label'] = temperature_to_label[answer_temperature]\n",
    "            row['correct'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_temperature.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1128.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# N-way temporal reasoning sentences with months\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} on the {date}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_date.csv\")\n",
    "actions = actions['action']\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions.str.contains('his|her', case=False)]\n",
    "actions = actions.tolist()\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "    month = date.strftime('%B')\n",
    "\n",
    "    # Sample a context\n",
    "    context = prompt.format(name=name, date=date_str, action='{action}')\n",
    "    df_people.append((name, date, context, month))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'context', 'month'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in tqdm(range(num_samples//len(date_ranges))):\n",
    "            action = random.choice(actions)\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            # Sample N unique names and dates, of which one is in a unique month\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['month'].value_counts().min() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "            # Find the person with the unique month\n",
    "            unique_month = sample['month'].value_counts().sample(frac=1.0).idxmin()\n",
    "            answer_person = sample[sample['month'] == unique_month]\n",
    "            # answer_idx = answer_person.index[0]\n",
    "            answer_date = answer_person['date'].iloc[0]\n",
    "            answer_name = answer_person['name'].iloc[0]\n",
    "            answer_month = answer_person['month'].iloc[0]\n",
    "\n",
    "            contexts = sample['context'].tolist()\n",
    "            context = \" \".join(contexts)\n",
    "            context = context + \" The only person that {action} in {answer_month} is\"\n",
    "            context = context.format(action=action, answer_month=answer_month)\n",
    "            \n",
    "            row = {}\n",
    "            alternatives = []\n",
    "            for i, (n, d) in enumerate(zip(sample['name'], sample['date'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                alternatives.append(n)\n",
    "            row['alternatives'] = alternatives\n",
    "            row['context'] = context\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_month'] = answer_month\n",
    "            row['correct_month_label'] = answer_date.month - 1\n",
    "            row['correct'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/date_{N}way_month.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n",
      "Date change count: 219\n",
      "Percentage of date change: 0.219\n"
     ]
    }
   ],
   "source": [
    "# Time of day reasoning - actions\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} at {time}.\"\n",
    "time_start = datetime.time(hour=0, minute=0)\n",
    "time_end = datetime.time(hour=23, minute=59)\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_time_of_day.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "# Drops actions that contain 'his' or 'her' across actions_present, actions_past\n",
    "actions = actions[~actions['actions_present'].str.contains('his|her', case=False)]\n",
    "actions = actions[~actions['actions_past'].str.contains('his|her', case=False)]\n",
    "actions = actions.values.tolist()\n",
    "\n",
    "# Create a list of all times of day between time_start and time_end with 15 minute intervals\n",
    "times = []\n",
    "for hour in range(time_start.hour, time_end.hour + 1):\n",
    "    for minute in range(0, 60, 15):\n",
    "        if hour == time_start.hour and minute < time_start.minute:\n",
    "            continue\n",
    "        if hour == time_end.hour and minute > time_end.minute:\n",
    "            continue\n",
    "        times.append(datetime.time(hour, minute))\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a time from list\n",
    "    time = random.choice(times)\n",
    "    if time.hour < 10 and time.hour != 0:\n",
    "        time_str = time.strftime(\"%-H:%M\").lower()\n",
    "    else:\n",
    "        time_str = time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "    # Generate the relevant context\n",
    "    context = prompt.format(name=name, time=time_str, action='{action_present}')\n",
    "    df_people.append((name, time, context))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'time', 'context'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_change_count = 0\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        action_present, action_past = random.choice(actions)\n",
    "        date_change_flag = False\n",
    "        # Sample random time in the time_start and time_end range\n",
    "        # sample from any possible value, not just the ones in times\n",
    "        current_time = datetime.time(random.randint(0, 23), random.randint(0, 59))\n",
    "        if current_time.hour < 10 and current_time.hour != 0:\n",
    "            current_time_str = current_time.strftime(\"%-H:%M\").lower()\n",
    "        else:\n",
    "            current_time_str = current_time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "        # Sample random date in the date_start and date_end range\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['time'].nunique() < N or sample['name'].nunique() < N:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \" \".join(contexts) + \" It is now {current_time_str}. The last person who {action_past} is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the {today_date}. The next person to celebrate their birthday is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the 31st of December. The next person to celebrate their birthday is\"\n",
    "        context = context.format(action_present=action_present, action_past=action_past, current_time_str=current_time_str)\n",
    "\n",
    "        # Find the person with the next birthday\n",
    "        next_time = sample[sample['time'] < current_time].sort_values(by='time', ascending=False).head(1)\n",
    "        if next_time.empty:\n",
    "            date_change_count += 1\n",
    "            date_change_flag = True\n",
    "            next_time = sample.sort_values(by='time', ascending=False).head(1)\n",
    "        answer_person = next_time\n",
    "        # answer_idx = answer_person.index[0]\n",
    "        answer_time = answer_person['time'].iloc[0]\n",
    "        answer_name = answer_person['name'].iloc[0]        \n",
    "\n",
    "        row = {}\n",
    "        alternatives = []\n",
    "        for i, (n, d) in enumerate(zip(sample['name'], sample['time'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'time_{i+1}'] = d\n",
    "            alternatives.append(n)\n",
    "        row['context'] = context\n",
    "        row['date_change'] = date_change_flag\n",
    "        row['alternatives'] = alternatives\n",
    "        row['correct_time'] = answer_time\n",
    "        row['correct_time_expr'] = answer_time.strftime(\"%-H:%M\").lower()\n",
    "        # Time diff in minutes\n",
    "        row['correct_time_diff'] = abs(datetime.datetime.combine(datetime.date.today(), answer_time) - datetime.datetime.combine(datetime.date.today(), current_time)).seconds // 60\n",
    "        row['correct'] = answer_name\n",
    "        row['time_idx_start'] = context.find(row['correct_time_expr'])\n",
    "        row['time_idx_end'] = row['time_idx_start'] + len(row['correct_time_expr'])\n",
    "\n",
    "        data.append(row)\n",
    "    print(f\"Date change count: {date_change_count}\")\n",
    "    print(f\"Percentage of date change: {date_change_count/num_samples}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/time_of_day_{N}way.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Time of day reasoning - phases\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "def classify_time_of_day(time):\n",
    "    if time.hour < 6:\n",
    "        return 'night'\n",
    "    elif time.hour < 12:\n",
    "        return 'morning'\n",
    "    elif time.hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "\n",
    "phase_to_label = {\n",
    "    'night': 0,\n",
    "    'morning': 1,\n",
    "    'afternoon': 2,\n",
    "    'evening': 3\n",
    "}\n",
    "\n",
    "N = 3\n",
    "prompt = \"{name} {action} at {time}.\"\n",
    "time_start = datetime.time(hour=0, minute=0)\n",
    "time_end = datetime.time(hour=23, minute=59)\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_time_of_day.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "# Drops actions that contain 'his' or 'her' across actions_present, actions_past\n",
    "actions = actions[~actions['actions_present'].str.contains('his|her', case=False)]\n",
    "actions = actions[~actions['actions_past'].str.contains('his|her', case=False)]\n",
    "actions = actions.values.tolist()\n",
    "\n",
    "# Create a list of all times of day between time_start and time_end with 15 minute intervals\n",
    "times = []\n",
    "for hour in range(time_start.hour, time_end.hour + 1):\n",
    "    for minute in range(0, 60, 15):\n",
    "        if hour == time_start.hour and minute < time_start.minute:\n",
    "            continue\n",
    "        if hour == time_end.hour and minute > time_end.minute:\n",
    "            continue\n",
    "        times.append(datetime.time(hour, minute))\n",
    "\n",
    "# Sample (names, date, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a time from list\n",
    "    time = random.choice(times)\n",
    "    if time.hour < 10 and time.hour != 0:\n",
    "        time_str = time.strftime(\"%-H:%M\").lower()\n",
    "    else:\n",
    "        time_str = time.strftime(\"%H:%M\").lower()\n",
    "\n",
    "    # Classify the phase of the day\n",
    "    phase = classify_time_of_day(time)\n",
    "\n",
    "    # Generate the relevant context\n",
    "    context = prompt.format(name=name, time=time_str, action='{action_present}')\n",
    "    df_people.append((name, time, context, phase))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'time', 'context', 'phase'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_change_count = 0\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        action_present, action_past = random.choice(actions)\n",
    "\n",
    "        # Sample random date in the date_start and date_end range\n",
    "        sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "        while sample['time'].nunique() < N or sample['name'].nunique() < N or sample['phase'].value_counts().min() > 1:\n",
    "            sample = df_people.sample(n=N, replace=False).reset_index(drop=True)\n",
    "\n",
    "        # Find the person with the unique phase\n",
    "        unique_phase = sample['phase'].value_counts().idxmin()\n",
    "        answer_person = sample[sample['phase'] == unique_phase]\n",
    "        # answer_idx = answer_person.index[0]\n",
    "        answer_time = answer_person['time'].iloc[0]\n",
    "        answer_name = answer_person['name'].iloc[0]\n",
    "        answer_phase = answer_person['phase'].iloc[0]\n",
    "        answer_phase_label = phase_to_label[answer_phase]\n",
    "\n",
    "        contexts = sample['context'].tolist()\n",
    "        context = \" \".join(contexts) + \" The only person that {action_present} in the {answer_phase} is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the {today_date}. The next person to celebrate their birthday is\"\n",
    "        # context = \" \".join(contexts) + f\" Today is the 31st of December. The next person to celebrate their birthday is\"\n",
    "        context = context.format(action_present=action_present, action_past=action_past, answer_phase=answer_phase)\n",
    "\n",
    "        row = {}\n",
    "        alternatives = []\n",
    "        for i, (n, d) in enumerate(zip(sample['name'], sample['time'])):\n",
    "            row[f'name_{i+1}'] = n\n",
    "            row[f'time_{i+1}'] = d\n",
    "            alternatives.append(n)\n",
    "        row['context'] = context\n",
    "        row['alternatives'] = alternatives\n",
    "        row['correct_time'] = answer_time\n",
    "        row['correct_time_expr'] = answer_time.strftime(\"%-H:%M\").lower()\n",
    "        row['correct'] = answer_name\n",
    "        row['correct_phase'] = answer_phase\n",
    "        row['correct_phase_label'] = answer_phase_label\n",
    "        row['time_idx_start'] = context.find(row['correct_time_expr'])\n",
    "        row['time_idx_end'] = row['time_idx_start'] + len(row['correct_time_expr'])\n",
    "        \n",
    "        data.append(row)    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/time_of_day_{N}way_phase.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "728aea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'Bob', 'Charlie', 'George', 'Kevin', 'Laura', 'Michael', 'Rachel', 'William', 'Aaron', 'Ian', 'Kyle', 'Martin', 'Rose', 'Marco', 'Andrew', 'Frank', 'Henry', 'Jack', 'Leon', 'Peter', 'Scott', 'Grant', 'Neil', 'Dean', 'Hope', 'April', 'Connor', 'Brandon', 'Joy', 'Emily', 'Hunter', 'Tyler', 'Blake', 'Dallas', 'Walker', 'John', 'Fred', 'Steve', 'Matt', 'Luke', 'Richard', 'Maria', 'Jerry', 'Robert', 'Mark', 'Max', 'Jason', 'Alex', 'Josh', 'Ryan']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "# Duration reasoning sentences\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Function to get the ordinal suffix for a day\n",
    "def ordinal(n):\n",
    "    return f\"{n}{'st' if n in (1, 21, 31) else 'nd' if n in (2, 22) else 'rd' if n in (3, 23) else 'th'}\"\n",
    "\n",
    "N = 3\n",
    "# prompt = \"{name}'s subscription starts on the {date} and lasts for {duration}.\"\n",
    "min_date = datetime.datetime(2019, 1, 1)\n",
    "max_date = datetime.datetime(2019, 12, 31)\n",
    "\n",
    "names = pd.read_csv(\"datasets/templates/names.csv\")\n",
    "names = names['name'].tolist()\n",
    "print(names)\n",
    "print(len(names))\n",
    "\n",
    "actions = pd.read_csv(\"datasets/generated/actions_duration.csv\")\n",
    "actions = actions.drop_duplicates()\n",
    "actions = actions[~actions['action'].str.contains('his|her', case=False)]\n",
    "\n",
    "duration_days = ['1 day', '2 days', '3 days', '4 days', '5 days', '6 days', '7 days', '8 days', '9 days', '10 days']\n",
    "length_days = [datetime.timedelta(days=1), datetime.timedelta(days=2), datetime.timedelta(days=3),\n",
    "               datetime.timedelta(days=4), datetime.timedelta(days=5), datetime.timedelta(days=6),\n",
    "               datetime.timedelta(days=7), datetime.timedelta(days=8), datetime.timedelta(days=9), datetime.timedelta(days=10)]\n",
    "duration_weeks = ['1 week', '2 weeks', '3 weeks', '4 weeks',\n",
    "                  '7 days', '10 days', '14 days', '21 days', '25 days', '30 days']\n",
    "length_weeks = [datetime.timedelta(weeks=1), datetime.timedelta(weeks=2), datetime.timedelta(weeks=3), datetime.timedelta(weeks=4),\n",
    "                    datetime.timedelta(days=7), datetime.timedelta(days=10), datetime.timedelta(days=14),\n",
    "                    datetime.timedelta(days=21), datetime.timedelta(days=25), datetime.timedelta(days=30)]\n",
    "duration_months = ['1 month', '2 months', '3 months', '4 months', '6 months', '8 months',\n",
    "                    '4 weeks', '6 weeks', '8 weeks', '10 weeks']\n",
    "length_months = [datetime.timedelta(days=30), datetime.timedelta(days=30*2), datetime.timedelta(days=30*3), datetime.timedelta(days=30*4),\n",
    "                    datetime.timedelta(days=30*6), datetime.timedelta(days=30*8),\n",
    "                    datetime.timedelta(weeks=4), datetime.timedelta(weeks=6), datetime.timedelta(weeks=8), datetime.timedelta(weeks=10)]\n",
    "duration_years = ['1 year', '2 years', '3 years', '4 years',\n",
    "                  '12 months', '18 months', '24 months', '36 months']\n",
    "length_years = [datetime.timedelta(days=365), datetime.timedelta(days=365*2), datetime.timedelta(days=365*3), datetime.timedelta(days=365*4),\n",
    "                    datetime.timedelta(days=30*12), datetime.timedelta(days=30*18), datetime.timedelta(days=30*24), datetime.timedelta(days=30*36)]\n",
    "\n",
    "# Sample (names, date, duration, context)\n",
    "df_people = []\n",
    "for i in range(1000):\n",
    "    # Sample a name\n",
    "    name = random.choice(names)\n",
    "    # Sample a date\n",
    "    date = min_date + (max_date - min_date) * random.random()\n",
    "    date = date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_str = f\"{ordinal(date.day)} of {date.strftime('%B')}\"\n",
    "\n",
    "    # Sample a duration type\n",
    "    duration_type, durations, durations_str = random.choice([('days',length_days, duration_days),\n",
    "                                                ('weeks', length_weeks, duration_weeks),\n",
    "                                                ('months', length_months, duration_months),\n",
    "                                                ('years', length_years, duration_years)])\n",
    "    # Sample a duration\n",
    "    idx_duration = random.randint(0, len(durations)-1)\n",
    "    duration = durations[idx_duration]\n",
    "    duration_str = durations_str[idx_duration]\n",
    "    duration_length = duration.days\n",
    "\n",
    "    # Compute the corresponding end date\n",
    "    # NB: this is only approximate, as it does not take into account leap years or month lengths\n",
    "    end_date = date + duration\n",
    "\n",
    "    # Generate the relevant context\n",
    "    # context = prompt.format(name=name, date=date_str, duration=duration_str, action='{action}')\n",
    "    df_people.append((name, date, end_date, duration, duration_str, duration_length, duration_type))\n",
    "\n",
    "df_people = pd.DataFrame(df_people, columns=['name', 'date', 'end_date', 'duration', 'duration_str', 'duration_length', 'duration_type'])\n",
    "df_people = df_people.drop_duplicates()\n",
    "\n",
    "def create_sampled_df(df_people, N, num_samples):\n",
    "    date_ranges = [\n",
    "        # (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 12, 31)),\n",
    "        (datetime.datetime(2019, 1, 1), datetime.datetime(2019, 2, 28)),\n",
    "        (datetime.datetime(2019, 3, 1), datetime.datetime(2019, 4, 30)),\n",
    "        (datetime.datetime(2019, 5, 1), datetime.datetime(2019, 6, 30)),\n",
    "        (datetime.datetime(2019, 7, 1), datetime.datetime(2019, 8, 31)),\n",
    "        (datetime.datetime(2019, 9, 1), datetime.datetime(2019, 10, 31)),\n",
    "        (datetime.datetime(2019, 11, 1), datetime.datetime(2019, 12, 31)),\n",
    "\n",
    "        (datetime.datetime(2019, 2, 1), datetime.datetime(2019, 3, 31)),\n",
    "        (datetime.datetime(2019, 4, 1), datetime.datetime(2019, 5, 31)),\n",
    "        (datetime.datetime(2019, 6, 1), datetime.datetime(2019, 7, 31)),\n",
    "        (datetime.datetime(2019, 8, 1), datetime.datetime(2019, 9, 30)),\n",
    "        (datetime.datetime(2019, 10, 1), datetime.datetime(2019, 11, 30)),\n",
    "        (datetime.datetime(2019, 12, 1), datetime.datetime(2019, 12, 31)),\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start_date, end_date in date_ranges:\n",
    "        # Filter the dataframe to get people born in the date range\n",
    "        df_people_filtered = df_people[(df_people['date'] >= start_date) & (df_people['date'] <= end_date)]\n",
    "\n",
    "        for _ in range(num_samples//len(date_ranges)):\n",
    "\n",
    "            # Sample random date in the date_start and date_end range\n",
    "            # target_date = date_start + datetime.timedelta(days=random.randint(0, 364))\n",
    "\n",
    "\n",
    "            sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            while sample['date'].nunique() < N or sample['name'].nunique() < N or sample['duration_type'].nunique() > 1:\n",
    "                sample = df_people_filtered.sample(n=N, replace=False).reset_index(drop=True)\n",
    "            \n",
    "            duration_type = sample['duration_type'].iloc[0]\n",
    "\n",
    "            # Sample a random action compatible with the duration type\n",
    "            action = actions.sample()\n",
    "            while action[duration_type].item() is False:\n",
    "                action = actions.sample()\n",
    "\n",
    "            context = action['action'].item()\n",
    "            contexts = [context.format(name=s['name'], date=f\"{ordinal(s['date'].day)} of {s['date'].strftime('%B')}\",\n",
    "                                        duration=s['duration_str']) for i, s in sample.iterrows()]\n",
    "            context = \" \".join(contexts) + f\" The person whose {action['activity'].item()} ends first is\"\n",
    "\n",
    "            answer_person = sample.sort_values(by='end_date').head(1).iloc[0]\n",
    "            answer_date = answer_person['date']\n",
    "            answer_end_date = answer_person['end_date']\n",
    "            answer_duration = answer_person['duration']\n",
    "            answer_duration_str = answer_person['duration_str']\n",
    "            answer_duration_length = answer_person['duration_length']\n",
    "            answer_name = answer_person['name']\n",
    "\n",
    "            row = {}\n",
    "            for i, (n, d, dur_str) in enumerate(zip(sample['name'], sample['date'], sample['duration_str'])):\n",
    "                row[f'name_{i+1}'] = n\n",
    "                row[f'date_{i+1}'] = d\n",
    "                row[f'duration_str_{i+1}'] = dur_str\n",
    "            row['context'] = context\n",
    "            row['duration_type'] = duration_type\n",
    "            # row['year_change'] = False if min_col == 'diff' else True\n",
    "            # row['distance'] = answer_person[min_col].days\n",
    "            row['correct_date'] = answer_date\n",
    "            row['correct_date_expr'] = f\"the {ordinal(answer_date.day)} of {answer_date.strftime('%B')}\"\n",
    "            row['correct_end_date'] = answer_end_date\n",
    "            row['correct_duration'] = answer_duration\n",
    "            row['correct_duration_str'] = answer_duration_str\n",
    "            row['correct_duration_length'] = answer_duration_length\n",
    "            row['correct_month'] = answer_date.strftime('%B')\n",
    "            row['correct'] = answer_name\n",
    "\n",
    "            data.append(row)\n",
    "    data = pd.DataFrame(data)\n",
    "    # print(f\"Year change count: {data['year_change'].sum()}\")\n",
    "    # print(f\"Percentage of year change: {data['year_change'].sum()/num_samples}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "df_sampled = create_sampled_df(df_people, N=N, num_samples=1000)\n",
    "\n",
    "df_sampled.to_csv(f\"datasets/templates/duration_{N}way.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
